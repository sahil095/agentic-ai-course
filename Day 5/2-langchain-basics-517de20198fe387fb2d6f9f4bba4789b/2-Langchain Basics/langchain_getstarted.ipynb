{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e5503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f25f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking and Tracing \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd14bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=GROQ_BASE_URL,  # Important!\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=1  \n",
    "\n",
    ")\n",
    "# response = llm.invoke(\"What is Agentic AI?\")\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b61a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8d5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model = \"qwen-qwq-32b\")\n",
    "response = model.invoke(\"What is Agentic AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8bed123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me an answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me an answer based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me an answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001350D5A5FD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001350D5A70E0>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chaining\n",
    "chain = prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0812dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\": \"What do you know about Agentic AI? and How to get Started? List down all the Opensource tools and resources.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef52885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, I need to explain what Agentic AI is. Let me start by recalling that Agentic AI refers to systems that can perform tasks autonomously, maybe even learn and adapt. I remember reading that it's related to agent-based systems, where each \"agent\" can make decisions and work together. So, each agent might have its own goals and can interact with others. But I should confirm if that's accurate.\n",
      "\n",
      "Then the user wants to know how to get started. I should outline steps someone can take to begin working with Agentic AI. Probably start with learning the basics, then experimenting with simple projects, and then moving to more complex tools. Maybe mention key concepts like autonomy, adaptability, and collaboration.\n",
      "\n",
      "Now, listing open-source tools and resources. Let me think about frameworks or libraries. There's something called the OpenAI Gym, but that's more for RL. Maybe ROS (Robot Operating System) is relevant since robotics often uses agent-based systems. Then there's the Agent-Based Modeling (ABM) tools like NetLogo, but that's more for social simulations. Oh, and there's the Multi-Agent Reinforcement Learning (MARL) frameworks like PettingZoo or Clean-MARL. I should also mention Python libraries like Pyro for probabilistic models, which might be part of creating autonomous agents.\n",
      "\n",
      "Wait, I should check if there's a specific Agentic AI framework. Maybe the Agent-Based Modeling (ABM) community uses tools like Mesa in Python. Mesa is an open-source ABM framework. Also, the Jason platform for agent-based programming using AgentSpeak. And maybe tools like Webots for simulating robots, which act as agents.\n",
      "\n",
      "I need to list all the open-source tools. Let's categorize them: for development, simulation, learning, and resources. Under development, Mesa, Jason (Java), Pyro, and others. Simulation tools could include Gazebo, CoppeliaSim, or even Unity with ML agents. Learning resources would be MOOCs on Coursera about AI, multi-agent systems, and books like \"Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations\" by Shoham and Leyton-Brown.\n",
      "\n",
      "Wait, also, maybe frameworks like Flatland for railway logistics agents? Or the RLPy (Reinforcement Learning Python) library. I should verify if those are open-source. Also, the Multi-Agent Deep Reinforcement Learning (MADRL) libraries like CleanRL's multi-agent examples. \n",
      "\n",
      "I should also mention the importance of understanding foundational AI concepts like RL, game theory, and distributed systems. Maybe suggest starting with a simple project, like a multi-agent environment in Mesa where agents follow some rules, then scaling up to MARL with PettingZoo.\n",
      "\n",
      "Possible steps to get started: Learn core AI concepts, pick a domain (robotics, games, economics), choose a framework, build a project, and engage with communities. Also, resources like GitHub repositories, papers, and online courses.\n",
      "\n",
      "Hmm, I need to ensure I'm not missing any key tools. Let me think again. For reinforcement learning in multi-agent settings, MARLlib by Ray could be useful. Also, the MAPE-K framework for agent architecture. Maybe include that in concepts.\n",
      "\n",
      "Wait, the user also asked for all open-source tools. I should check if there are more. Like the Agent-Based Computational Economics (ACE) tools, or the MASON framework in Java. Also, perhaps the Multi-Agent Programming (MAP) languages like AgentSpeak. Oh, and the AnyLogic has an open-source version? Wait, AnyLogic is commercial, so maybe not. Stick to confirmed open-source ones.\n",
      "\n",
      "So compiling all of this into a structured answer. Start with a definition, then steps to get started, then list the tools categorized, and resources. Need to make sure each tool is open-source. Let me list them again:\n",
      "\n",
      "Development tools:\n",
      "- Mesa (Python)\n",
      "- Jason (Java)\n",
      "- Pyro (probabilistic reasoning)\n",
      "- PettingZoo (MARL)\n",
      "- Clean-MARL\n",
      "- RLlib's MARL components\n",
      "\n",
      "Simulation tools:\n",
      "- Gazebo (robotics)\n",
      "- CoppeliaSim\n",
      "- NetLogo (though maybe not open-source? Wait, NetLogo is free for academic use but not open-source. Maybe better to exclude if not truly open-source.)\n",
      "\n",
      "Wait, NetLogo's source code isn't open, so perhaps not. Then CoppeliaSim is free but not sure if open-source. Maybe better to stick with confirmed open-source ones like Gazebo (ROS's simulation), which is open-source. Also, OpenAI Gym has multi-agent extensions.\n",
      "\n",
      "Learning resources: Online courses, books, and papers. GitHub repos too.\n",
      "\n",
      "I need to make sure all listed tools are open-source. Let me confirm each:\n",
      "\n",
      "Mesa: Yes, Apache 2.0.\n",
      "\n",
      "Jason: AGPL-3.0.\n",
      "\n",
      "Pyro: MIT license.\n",
      "\n",
      "PettingZoo: Open-source under MIT.\n",
      "\n",
      "MADRL frameworks like CleanRL's examples are open.\n",
      "\n",
      "ROS is open-source, so that counts for simulation in robotics.\n",
      "\n",
      "Also, maybe mention Docker and cloud environments for deploying agents.\n",
      "\n",
      "Alright, structure the answer with sections on definition, getting started steps, tools categorized, and resources. Make sure to explain each tool briefly.\n",
      "\n",
      "Also, check if there's an official Agentic AI framework, but maybe the term is broader, so the tools are across different domains. Alright, time to put it all together coherently.\n",
      "</think>\n",
      "\n",
      "### What is Agentic AI?\n",
      "Agentic AI refers to systems composed of **autonomous agents** that can perceive their environment, make decisions, and act to achieve specific goals. These agents can be simple or complex, operate individually or collaboratively, and adapt to dynamic conditions. Key characteristics include:\n",
      "- **Autonomy**: Agents act independently.\n",
      "- **Reactivity/Proactiveness**: Respond to or anticipate environmental changes.\n",
      "- **Collaboration**: Coordinate with other agents (e.g., in multi-agent systems).\n",
      "- **Learning**: Adapt through reinforcement learning (RL), machine learning (ML), or evolutionary algorithms.\n",
      "\n",
      "### How to Get Started with Agentic AI\n",
      "1. **Understand Core Concepts**:\n",
      "   - Learn foundational AI/ML (e.g., Python, TensorFlow, PyTorch).\n",
      "   - Study **multi-agent systems**, game theory, and distributed systems.\n",
      "   - Explore agent architectures (BDI, reactive, or hybrid models).\n",
      "\n",
      "2. **Choose a Domain**:\n",
      "   - Start with simple scenarios (e.g., traffic simulations, game AI) before tackling robotics or complex social systems.\n",
      "\n",
      "3. **Pick a Framework/Tool**:\n",
      "   - Use open-source tools (listed below) to build and simulate agents.\n",
      "\n",
      "4. **Build a Project**:\n",
      "   - Start small (e.g., a basic agent in Mesa or PettingZoo).\n",
      "   - Scale to multi-agent environments (e.g., MARL in PettingZoo or ROS for robotics).\n",
      "\n",
      "5. **Experiment and Iterate**:\n",
      "   - Test agents in simulated environments, refine behaviors, and optimize performance.\n",
      "\n",
      "---\n",
      "\n",
      "### Open-Source Tools & Resources for Agentic AI\n",
      "\n",
      "#### **1. Development & Simulation Frameworks**\n",
      "| **Tool**          | **Description**                                                                 | **Use Case**                          | **GitHub/Website**                              |\n",
      "|-------------------|---------------------------------------------------------------------------------|---------------------------------------|-----------------------------------------------|\n",
      "| **Mesa**          | Python framework for agent-based modeling (ABM). Simulate social, economic, or ecological systems. | Social simulations, epidemiology    | [GitHub](https://github.com/projectmesa/mesa) |\n",
      "| **Jason**         | Java-based BDI (Belief-Desire-Intention) agent framework. Implements AgentSpeak. | Complex decision-making agents.       | [Website](http://jason-ares.org/)            |\n",
      "| **Pyro**          | Probabilistic programming library for building agents with Bayesian reasoning.  | Uncertain environments, robotics.   | [GitHub](https://github.com/probcomp/pyro)   |\n",
      "| **PettingZoo**    | MARL (Multi-Agent Reinforcement Learning) environment framework (extends Gym).   | Competitive/cooperative games, robotics. | [GitHub](https://github.com/Farama-Foundation/PettingZoo) |\n",
      "\n",
      "#### **2. Reinforcement Learning & Multi-Agent Learning**\n",
      "| **Tool**          | **Description**                                                                 | **Use Case**                          | **GitHub/Website**                              |\n",
      "|-------------------|---------------------------------------------------------------------------------|---------------------------------------|-----------------------------------------------|\n",
      "| **Clean-MARL**     | Modular library for MARL research, built on PyTorch.                            | Training cooperative/competitive agents | [GitHub](https://github.com/hqucms/Clean-MARL) |\n",
      "| **MARLlib**       | Ray’s framework for distributed MARL (part of the Ray ecosystem).               | Large-scale distributed MARL.         | [GitHub](https://github.com/ray-project/ray)   |\n",
      "| **MadMario**      | Research platform for MARL using the Super Mario Bros game for training.        | Game AI, benchmarking MARL algorithms | [GitHub](https://github.com/igncvg/madmario)   |\n",
      "\n",
      "#### **3. Robotics & Physical Agents**\n",
      "| **Tool**          | **Description**                                                                 | **Use Case**                          | **GitHub/Website**                              |\n",
      "|-------------------|---------------------------------------------------------------------------------|---------------------------------------|-----------------------------------------------|\n",
      "| **ROS (Robot Operating System)**         | Middleware for building robot agents. Includes Gazebo for simulation. | Robotics, autonomous systems.          | [Website](https://ros.org/)                    |\n",
      "| **Gazebo**         | 3D simulation for robots (part of ROS).                                          | Testing robot agents.                 | [ROS Wiki](https://wiki.ros.org/gazebo)        |\n",
      "| **CoppeliaSim**    | 3D simulation for robotics and computer vision.                                  | Agent-robot interaction.               | [Website](https://www.coppeliarobotics.com/)   |\n",
      "\n",
      "#### **4. Game-Based Environments**\n",
      "| **Tool**          | **Description**                                                                 | **Use Case**                          | **GitHub/Website**                              |\n",
      "|-------------------|---------------------------------------------------------------------------------|---------------------------------------|-----------------------------------------------|\n",
      "| **Minecraft (Malmo)** | Microsoft’s framework for AI research in Minecraft.                              | Complex decision-making, exploration. | [GitHub](https://github.com/Microsoft/malmo)    |\n",
      "| **Sonic the Hedgehog (Sonic)** | OpenAI’s framework for training agents in Sonic games.                   | Reinforcement learning benchmarks.     | [GitHub](https://github.com/openai/sonic-mario) |\n",
      "\n",
      "#### **5. General AI & Learning Libraries**\n",
      "| **Tool**          | **Description**                                                                 | **Use Case**                          | **GitHub/Website**                              |\n",
      "|-------------------|---------------------------------------------------------------------------------|---------------------------------------|-----------------------------------------------|\n",
      "| **PyTorch/RLlib** | PyTorch with RLlib extension for scalable RL, including MARL.                    | Training neural network-based agents. | [GitHub](https://github.com/pytorch/rl)        |\n",
      "| **TensorFlow Agents** | TensorFlow library for RL and agents.                                         | Deep reinforcement learning.          | [GitHub](https://github.com/tensorflow/agents) |\n",
      "\n",
      "#### **6. Educational & Documentation Tools**\n",
      "| **Resource**       | **Description**                                                                 | **Link**                              |\n",
      "|--------------------|---------------------------------------------------------------------------------|---------------------------------------|\n",
      "| **Mesa Tutorials**  | Guides for Mesa and agent-based modeling.                                        | [Mesa Docs](https://mesa.readthedocs.io) |\n",
      "| **Jason Documentation** | Tutorials for BDI agents with AgentSpeak.                                      | [Jason Docs](http://jason-ares.org/Documentation/) |\n",
      "| **PettingZoo Tutorials** | Step-by-step MARL projects (e.g., training agents in Pong).                   | [PettingZoo Docs](https://pettingzoo.farama.org/) |\n",
      "\n",
      "---\n",
      "\n",
      "### Key Resources for Learning\n",
      "1. **Courses**:\n",
      "   - **Multi-Agent Systems** on Coursera (e.g., \"Multi-Agent Systems\" by The University of Queensland).\n",
      "   - **Reinforcement Learning Specialization** on Coursera (covers MARL basics).\n",
      "\n",
      "2. **Books**:\n",
      "   - *Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations* by Shoham & Leyton-Brown.\n",
      "   - *Reinforcement Learning: An Introduction* (Sutton & Barto).\n",
      "\n",
      "3. **Papers & Blogs**:\n",
      "   - *MARL papers on arXiv*: Search for \"multi-agent reinforcement learning\" or \"agent-based modeling\".\n",
      "   - Blogs like *AI Blog* or *OpenAI’s blog* for MARL advancements.\n",
      "\n",
      "4. **Communities**:\n",
      "   - **GitHub**: Search for repositories like `multi-agent-systems` or `agent-based-modeling`.\n",
      "   - **Reddit**: r/AI, r/ReinforcementLearning, r/MultiAgentSystems.\n",
      "   - **Stack Overflow**: Tag filters like `multi-agent-systems` or `reinforcement-learning`.\n",
      "\n",
      "---\n",
      "\n",
      "### Example Project Ideas to Get Started\n",
      "1. **Simple Agent-Based Model (Mesa)**:\n",
      "   - Build a traffic simulation where cars (agents) navigate roads and adjust speeds based on rules.\n",
      "\n",
      "2. **Multi-Agent Game (PettingZoo)**:\n",
      "   - Train two agents to compete in a simple game like \"Tic-Tac-Toe\" using MARL.\n",
      "\n",
      "3. **Robotics Simulation (ROS/Gazebo)**:\n",
      "   - Create a robot agent in Gazebo that navigates a maze using sensors and reinforcement learning.\n",
      "\n",
      "---\n",
      "\n",
      "### Final Tips\n",
      "- **Start Small**: Begin with Mesa or PettingZoo before diving into complex robotics.\n",
      "- **Experiment**: Use GitHub repos like [MARL-baselines](https://github.com/younggyoseo/MARL-baselines) for prebuilt MARL examples.\n",
      "- **Stay Updated**: Follow research papers and conferences like IJCAI’s Multi-Agent Systems track.\n",
      "\n",
      "By leveraging these tools and resources, you can build and experiment with agentic systems tailored to your goals!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14828cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86eb0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"What do you know about Agentic AI? and How to get Started? List down all the Opensource tools and resources.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d05122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user is asking about Agentic AI, how to get started, and wants a list of open-source tools and resources. Let me start by recalling what Agentic AI actually is. From what I remember, Agentic AI refers to systems where multiple artificial agents work together to achieve complex tasks. These agents can be autonomous or semi-autonomous and might coordinate through communication or collaboration. It's similar to Multi-Agent Systems (MAS) from what I've studied before.\n",
      "\n",
      "First, I should define Agentic AI clearly so the user understands the basics. Maybe mention that it's an approach where individual AI agents collaborate, each with their own objectives, and together they solve problems more effectively than a single AI could. Examples might include things like traffic management systems, supply chain optimization, or even video games where NPCs interact.\n",
      "\n",
      "Next, they want to know how to get started. Breaking this down, the steps would involve learning the fundamentals, choosing a problem, selecting a framework, building and testing agents, and iterating. I should outline these steps in a logical order, starting from education to practical implementation.\n",
      "\n",
      "For the tools and resources, since the user asked for open-source, I need to list frameworks and tools that are free and available. Let me think of the major ones. The first that comes to mind is the Multi-Agent Reinforcement Learning (MARL) framework. OpenAI's Gym has some multi-agent environments, so that's a good start. Then there's the MARLlib, which is part of RLlib from Ray. Another one is the MAgent framework from Alibaba, which is designed for large-scale simulations. Also, the PettingZoo project, which extends Gym to multi-agent scenarios. \n",
      "\n",
      "I should also mention simulation platforms like Gazebo for robotics, which can be used in multi-agent scenarios. Then there's the MAgent mentioned earlier. For communication, maybe something like the CommAI gym. Tools for agent-based modeling like Netlogo (though that's not open-source, wait, is it free? Let me check. Netlogo is free for academic use, but maybe not open-source. Hmm, maybe better to stick with definitely open-source ones. \n",
      "\n",
      "Programming languages: Python is the go-to for AI, so mentioning that makes sense. Libraries like TensorFlow and PyTorch have extensions for multi-agent systems. Also, the Python library PettingZoo is key here. \n",
      "\n",
      "Documentation and tutorials: The official MARLlib documentation, the PettingZoo GitHub, maybe some research papers on arXiv, and online courses. \n",
      "\n",
      "Wait, the user might also benefit from community resources like forums or GitHub repositories. Including links to GitHub repos for the tools listed would be helpful. \n",
      "\n",
      "Wait, I should make sure all the tools listed are indeed open-source. Let me verify each one:\n",
      "\n",
      "- MARLlib (Ray's RLlib): Yes, Ray is open-source under Apache 2.0.\n",
      "- PettingZoo: Definitely open-source, MIT license.\n",
      "- MAgent: Alibaba's MAgent is open-source on GitHub.\n",
      "- OpenAI Gym: Open-source, MIT license, though the original is more single-agent but extensions exist for multi-agent.\n",
      "- Gazebo: Yes, part of ROS, which is open-source.\n",
      "- Any others? Maybe the Multi-Agent Deep Reinforcement Learning framework (MADDPG) implementations? The original paper's code might not be a framework but implementations exist on GitHub. \n",
      "\n",
      "Also, the LightGBM or other ML libraries? Not specifically for multi-agent, maybe not. Focus on the ones specifically for multi-agent.\n",
      "\n",
      "For resources, maybe some MOOCs like Coursera's AI courses that cover multi-agent systems. The book \"Multi-Agent Systems\" by Shoham and Leyton-Brown is a classic, though I'm not sure if it's free. The user might need to access it via a university library. \n",
      "\n",
      "Putting this all together, the answer should be structured with a definition, steps to get started, then a bullet-point list of tools, and another for resources. Need to make sure the steps are clear and practical, not too technical but enough to guide someone new. Also, check for any recent tools I might have missed. Maybe the MAgent framework from Alibaba is a good one, and also look into PyMARL, a Python library for multi-agent RL. \n",
      "\n",
      "Also, mentioning platforms like Google's OpenAI's Multi-Agent environments, and maybe the SMAC (StarCraft: Multi-Agent Challenge) which is an environment for MARL. But is that open-source? SMAC is part of SC2LE, which is open-source, so that's okay. \n",
      "\n",
      "I should also include the MARLlib's documentation as a resource, and maybe some GitHub repositories for example implementations. \n",
      "\n",
      "Okay, I think that covers the main points. Now, organize all this into a coherent answer with clear sections. Make sure the tools are all open-source and relevant. Avoid any that aren't, like Netlogo if it's not open-source. \n",
      "\n",
      "Double-checking each tool's licensing. RLlib is under Apache 2.0, PettingZoo is MIT, MAgent is Apache 2.0 too. Gazebo is under the GNU GPL. SMAC is part of StarCraft II Learning Environment, which is free to use for research. \n",
      "\n",
      "Alright, compiling all of this into the answer structure now.\n",
      "</think>\n",
      "\n",
      "### What is Agentic AI?  \n",
      "**Agentic AI** (or Multi-Agent Systems) refers to systems composed of multiple autonomous or semi-autonomous agents that collaborate, compete, or coexist to achieve complex tasks. These agents can be software programs, robots, or even humans, each equipped with decision-making capabilities and often operating in shared or distributed environments. Key features include:  \n",
      "- **Autonomy**: Agents operate independently but can coordinate.  \n",
      "- **Decentralization**: No central authority; agents act based on local information.  \n",
      "- **Collaboration/Competition**: Agents may work together or oppose each other to achieve goals.  \n",
      "- **Adaptability**: Agents learn and adapt to dynamic environments.  \n",
      "\n",
      "Common applications include:  \n",
      "- Robotics (e.g., swarm robotics for search-and-rescue).  \n",
      "- Supply chain optimization.  \n",
      "- Game AI (e.g., NPC behavior in video games).  \n",
      "- Smart cities (e.g., traffic management systems).  \n",
      "- Distributed computing and blockchain.  \n",
      "\n",
      "---\n",
      "\n",
      "### How to Get Started with Agentic AI  \n",
      "1. **Learn the Fundamentals**:  \n",
      "   - Study **multi-agent reinforcement learning (MARL)**, game theory, and distributed systems.  \n",
      "   - Familiarize yourself with core concepts like **cooperative vs. competitive learning**, **communication protocols**, and **coordination algorithms**.  \n",
      "\n",
      "2. **Choose a Domain/Problem**:  \n",
      "   - Start with a simple problem (e.g., a cooperative game, traffic light control, or a simulated environment like the **StarCraft II Learning Environment**).  \n",
      "\n",
      "3. **Select a Framework/Tool**:  \n",
      "   - Use open-source tools (listed below) to build and test agents.  \n",
      "\n",
      "4. **Prototype Agents**:  \n",
      "   - Implement basic agents and test their interactions. Use environments like **PettingZoo** or **MARLlib** to simulate multi-agent scenarios.  \n",
      "\n",
      "5. **Train and Optimize**:  \n",
      "   - Train agents using algorithms like **MADDPG** or **QMIX**. Use reinforcement learning (RL) techniques tailored for multi-agent settings.  \n",
      "\n",
      "6. **Iterate and Experiment**:  \n",
      "   - Test different strategies (e.g., centralized training vs. decentralized execution) and analyze agent behaviors.  \n",
      "\n",
      "---\n",
      "\n",
      "### Open-Source Tools and Resources  \n",
      "\n",
      "#### **1. Frameworks & Simulators**  \n",
      "| **Tool**               | **Description**                                                                 | **Link**                                                                 |  \n",
      "|------------------------|---------------------------------------------------------------------------------|--------------------------------------------------------------------------|  \n",
      "| **PettingZoo**         | Multi-Agent extension of OpenAI Gym for RL. Supports turn-based and parallel agents. | [GitHub](https://github.com/Farama-Foundation/PettingZoo)                  |  \n",
      "| **MARLlib**            | Multi-Agent extension of RLlib (part of Ray). Implements algorithms like MADDPG. | [GitHub](https://github.com/ray-project/ray/tree/master/rllib/multi_agent) |  \n",
      "| **M.Agent (MAgent)**   | Alibaba’s large-scale 2D grid-world platform for complex multi-agent tasks.    | [GitHub](https://github.com/alibaba/MAgent)                               |  \n",
      "| **Mesa**               | Agent-based modeling (ABM) framework for social simulations.                    | [GitHub](https://github.com/projectmesa/mesa)                            |  \n",
      "| **OpenAI Gym Multi-Agent (Extensions)**       | Multi-agent environments (e.g., `simple_spread` in PettingZoo). | [PettingZoo Docs](https://pettingzoo.farama.org/)                        |  \n",
      "| **StarCraft II API**   | Google’s StarCraft II Learning Environment for MARL experiments.               | [GitHub](https://github.com/deepmind/pysc2)                              |  \n",
      "| **Gazebo**             | Robotic simulation tool for physical multi-agent systems.                      | [ROS Wiki](http://gazebosim.org/)                                       |  \n",
      "\n",
      "---\n",
      "\n",
      "#### **2. Algorithms & Libraries**  \n",
      "- **PyMARL**: A PyTorch-based library for MARL research. Implements algorithms like QMIX, QTRAN, and COMA.  \n",
      "  - [GitHub](https://github.com/oxwhirl/pymarl)  \n",
      "- **MADDPG Implementation**: Open-source code for the MADDPG algorithm.  \n",
      "  - [GitHub Example](https://github.com/openai/baselines) (though Baselines is deprecated, the idea is there).)  \n",
      "- **rllib (Ray’s RLlib)**: Includes multi-agent support in its distributed RL library.  \n",
      "  - [Ray Docs](https://docs.ray.io/en/latest/rllib/index.html)  \n",
      "\n",
      "---\n",
      "\n",
      "#### **3. Datasets & Environments**  \n",
      "- **PettingZoo Environments**: Pre-built multi-agent environments (e.g., `mpe` suite).  \n",
      "- **SMAC (StarCraft Multi-Agent Challenge)**: A set of challenging StarCraft II scenarios.  \n",
      "- **GridWorld**: Simple grid-based environments for testing coordination.  \n",
      "\n",
      "---\n",
      "\n",
      "#### **4. Learning Resources**  \n",
      "- **Books**:  \n",
      "  - *Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations* by Shoham & Leyton-Brown (free PDF available).)  \n",
      "  - *Reinforcement Learning: An Introduction* (covers MARL concepts).)  \n",
      "\n",
      "- **Papers & Surveys**:  \n",
      "  - [Multi-Agent Reinforcement Learning: A Survey (2020)](https://arxiv.org/abs/1810.05587)  \n",
      "  - [QMIX: Monotonic Value Factorisation for Deep Multi-Agent Reinforcement Learning (2018)](https://arxiv.org/abs/1803.11485)  \n",
      "\n",
      "- **Online Courses**:  \n",
      "  - [Coursera: Game Theory](https://www.coursera.org/learn/game-theory) (Basics of agent interactions.)  \n",
      "  - [edX: AI for Robotics](https://www.edx.org/course/ai-for-robotics) (Covers decentralized systems.)  \n",
      "\n",
      "- **Communities**:  \n",
      "  - [Multi-Agent Systems Stack Exchange](https://ai.stackexchange.com/questions/tagged/multi-agent)  \n",
      "  - GitHub repositories (e.g., search for \"multi-agent reinforcement learning\").  \n",
      "\n",
      "---\n",
      "\n",
      "#### **5. Example Workflow**  \n",
      "1. **Setup Environment**:  \n",
      "   ```bash  \n",
      "   pip install pettingzoo gym ray[rllib] torch  \n",
      "   ```  \n",
      "2. **Build a Simple Agent**:  \n",
      "   Use PettingZoo to create a two-agent coordination task (e.g., \"spread\" environment).  \n",
      "   ```python  \n",
      "   from pettingzoo.mpe import simple_spread_v2  \n",
      "   env = simple_spread_v2.env(N=2)  \n",
      "   # Train agents using MARL algorithms.  \n",
      "   ```  \n",
      "3. **Train Agents**:  \n",
      "   Use MARLlib or PyMARL to implement algorithms like MADDPG or QMIX.  \n",
      "\n",
      "---\n",
      "\n",
      "### Final Tips  \n",
      "- **Start Small**: Begin with basic environments like PettingZoo’s `simple_spread` before scaling up.  \n",
      "- **Experiment**: Test different communication protocols (e.g., discrete messages, continuous signals).  \n",
      "- **Collaborate**: Join open-source projects or Kaggle competitions (e.g., [Kaggle’s Multi-Agent Challenges](https://www.kaggle.com/competitions).  \n",
      "\n",
      "Agentic AI is a rapidly evolving field—stay updated with arXiv papers and GitHub contributions!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "json_output_parser = JsonOutputParser()\n",
    "json_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bacd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query \\n {format_instruction} \\n {query}\\n\",\n",
    "    input_variables=['query'],\n",
    "    partial_variables={\"format_instruction\": json_output_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "252ea867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction} \\n {query}\\n')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0c041f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model|json_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"query\": \"What do you know about Agentic AI? and How to get Started? List down all the Opensource tools and resources.\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18fbff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me an answer in json based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Assignment -- chatpromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "json_output_parser = JsonOutputParser()\n",
    "json_output_parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me an answer in json based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed6e3958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, so the user is asking about Agentic AI, how to get started with it, and wants a list of open-source tools and resources. Let me start by recalling what Agentic AI is. From what I remember, Agentic AI refers to systems where multiple autonomous agents collaborate to solve complex problems. Each agent has its own goals and acts independently, but together they achieve a common objective. It\\'s a bit like how different departments in a company work together towards the company\\'s goals. \\n\\nNow, the user also wants to know how to get started. So I should break that down into steps. First, maybe understanding the basics of AI and machine learning is essential. Then, diving deeper into multi-agent systems. Next, learning programming languages like Python, maybe frameworks like TensorFlow or PyTorch. Then, exploring specific libraries or tools designed for multi-agent systems.\\n\\nFor the open-source tools, I need to list them. Let me think. There\\'s MAgent, which is from Alibaba, right? It\\'s for large-scale multi-agent reinforcement learning. Then, there\\'s the Multi-Agent Learning and Interaction (MALIN) framework. OpenAI has some tools too, like the Multi-Agent Reinforcement Learning (MARL) library. Also, the GAMA platform for agent-based modeling. \\n\\nWait, what about PySC2? That\\'s for StarCraft II, which is used for developing AI agents in a complex environment. And the Multi-Agent Reinforcement Learning Gym (MARLlib) which is part of RLlib. \\n\\nOh, and there\\'s the Multi-Agent Decision Process (MADP) framework, but I think that\\'s been around for a while. Also, the Agent-Based Modeling (ABM) frameworks like NetLogo, but I should check if they\\'re open-source. NetLogo is open-source, yes. \\n\\nFor resources, the user might need academic papers, books, courses. The book \"Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations\" by Shoham and Leyton-Brown is a classic. Coursera has some courses on multi-agent systems. The conference AAMAS is relevant. Online tutorials like those on the official sites of the tools I mentioned would be good. \\n\\nWait, I should also mention GitHub repositories or communities. Maybe the Multi-Agent Reinforcement Learning GitHub page? Or specific projects like those using Mesa for ABM. \\n\\nI need to structure this into a JSON format as per the user\\'s request. The keys should be \"Explanation of Agentic AI\", \"Getting Started Steps\", \"Open Source Tools\", and \"Resources\". Under each step in \"Getting Started Steps\", I should provide detailed points. \\n\\nLet me verify the tools again. MAgent is definitely from Alibaba. GAMA is open-source. MARLlib is part of RLlib in Ray. StarCraft II\\'s PySC2 is still relevant? I think so. Also, maybe Sisl (the Social Intelligence Suite) from DeepMind? They have some tools for multi-agent systems. \\n\\nWait, and what about the MAgent vs. MARLlib? I should list them separately. Also, check if any other tools like the Multi-Agent Deep Reinforcement Learning (MADRL) framework. Hmm, maybe some are more niche. \\n\\nFor the resources, conferences like AAMAS and IJCAI. Also, forums like the Multi-Agent Systems subreddit or Stack Overflow tags. \\n\\nI should structure all these points into the JSON without markdown. Make sure each tool has a brief description and a link. The steps should guide from learning the basics to implementing projects. \\n\\nWait, under \"Getting Started Steps\": 1. Learn fundamentals of AI/ML. 2. Focus on Multi-Agent Systems (MAS) concepts. 3. Learn programming and frameworks. 4. Choose a project. 5. Explore specific use cases. 6. Collaborate and engage with communities.\\n\\nYes, that makes sense. The tools need to be listed with their purposes. Let me compile all that into the JSON structure now, making sure all the info is accurate and the links are correct. I should also mention documentation links for each tool. \\n\\nHmm, I might have missed some tools. Let me think again. Any other open-source tools? There\\'s the \"Multi-Agent Systems\" section in GitHub, maybe some specific repos like the \"Mesa\" framework for agent-based modeling in Python, which is open-source. Mesa is a good one. \\n\\nIncluding Mesa would add to the list. Also, the \"Piston\" library for multi-agent systems in Python. Or maybe \"Flow\", which is for multi-agent traffic scenarios. \\n\\nWait, Flow is developed by Berkeley, part of their traffic simulation projects. That\\'s another tool. \\n\\nI should also check if all these tools are still maintained. For example, MAgent is still active? Let me confirm. A quick check in my mind: MAgent\\'s GitHub repo is still up, I think. \\n\\nOkay, compiling all this into the JSON. Make sure the descriptions are concise. Alright, I think that\\'s covered. The user might also appreciate tips on communities or forums to join, like the Multi-Agent RL Discord or mailing lists. \\n\\nPutting it all together now. Ensure the JSON is properly formatted with commas and brackets, but since the user wants the answer in JSON, the final response should be that without any extra text. Let me structure each section step by step.\\n</think>\\n\\n{\\n  \"Explanation of Agentic AI\": \"Agentic AI refers to systems where multiple autonomous agents collaborate to solve complex problems. These agents operate with some level of independence, often in decentralized environments, and can interact with each other and their environment to achieve a common objective. Key characteristics include autonomy, coordination, and adaptability. Applications span robotics, gaming, logistics, and decentralized decision-making systems.\",\\n  \"Getting Started Steps\": [\\n    {\\n      \"Step 1\": \"Understand Core Concepts\",\\n      \"Description\": \"Study fundamental AI/ML concepts, including reinforcement learning, game theory, and distributed systems. Familiarize yourself with agent-based modeling and coordination strategies.\"\\n    },\\n    {\\n      \"Step 2\": \"Learn Programming & Frameworks\",\\n      \"Description\": \"Master Python and tools like TensorFlow, PyTorch, or RLlib. Explore multi-agent-specific libraries like MAgent or MARLlib.\"\\n    },\\n    {\\n      \"Step 3\": \"Choose a Project\",\\n      \"Description\": \"Start with simple projects like coordinating agents in a simulated environment (e.g., using GAMA or StarCraft II). Gradually tackle real-world scenarios like traffic management or robotics.\"\\n    },\\n    {\\n      \"Step 4\": \"Explore Use Cases\",\\n      \"Description\": \"Study applications in robotics (e.g., swarm robotics), economics (market simulations), or gaming (multiplayer AI).\"\\n    },\\n    {\\n      \"Step 5\": \"Engage with Communities\",\\n      \"Description\": \"Join forums like the Multi-Agent RL Discord, attend conferences (AAMAS, IJCAI), and participate in open-source projects.\"\\n    }\\n  ],\\n  \"Open Source Tools & Resources\": {\\n    \"Frameworks & Libraries\": [\\n      {\\n        \"Name\": \"MAgent\",\\n        \"Description\": \"A large-scale multi-agent reinforcement learning platform from Alibaba, supporting complex scenarios with thousands of agents.\",\\n        \"Link\": \"https://github.com/alibaba/AI-SCIENCE/tree/master/MAgent\"\\n      },\\n      {\\n        \"Name\": \"MARLlib\",\\n        \"Description\": \"Part of Ray\\'s RLlib, provides implementations of MARL algorithms (e.g., MADDPG, MAA2C).\",\\n        \"Link\": \"https://docs.ray.io/en/latest/rllib/multi-agent.html\"\\n      },\\n      {\\n        \"Name\": \"GAMA\",\\n        \"Description\": \"A Java-based platform for agent-based modeling, supporting complex spatial environments.\",\\n        \"Link\": \"https://gama-platform.org/\"\\n      },\\n      {\\n        \"Name\": \"Mesa\",\\n        \"Description\": \"A Python framework for agent-based modeling, ideal for simulating social, biological, or economic systems.\",\\n        \"Link\": \"https://mesa.readthedocs.io/\"\\n      },\\n      {\\n        \"Name\": \"StarCraft II API (PySC2)\",\\n        \"Description\": \"A library for developing and testing multi-agent AI in the StarCraft II game environment.\",\\n        \"Link\": \"https://github.com/deepmind/pysc2\"\\n      }\\n    ],\\n    \"Toolkits & Simulators\": [\\n      {\\n        \"Name\": \"Flow\",\\n        \"Description\": \"A traffic simulation toolkit using SUMO, designed for multi-agent traffic control.\",\\n        \"Link\": \"https://github.com/flow-rl/flow\"\\n      },\\n      {\\n        \"Name\": \"Sarl\",\\n        \"Description\": \"A Java-based framework for developing agent-based systems with modular components.\",\\n        \"Link\": \"https://www.sarl.io/\"\\n      },\\n      {\\n        \"Name\": \"OpenAI Gym Multi-Agent\",\\n        \"Description\": \"Extensions of OpenAI Gym for multi-agent scenarios, like MAPE (Multi-Agent Planning Environment).\",\\n        \"Link\": \"https://github.com/openai/gym\"\\n      }\\n    ],\\n    \"Research & Datasets\": [\\n      {\\n        \"Name\": \"Multi-Agent Reinforcement Learning (MARL) Surveys\",\\n        \"Description\": \"Papers like \\'Multi-Agent Reinforcement Learning: A Critical Review\\' provide foundational knowledge.\",\\n        \"Link\": \"https://arxiv.org/pdf/1810.05587.pdf\"\\n      },\\n      {\\n        \"Name\": \"MPE (Multi-Agent Particle Environment)\",\\n        \"Description\": \"A simple multi-agent environment for experimentation, part of the MAgent ecosystem.\",\\n        \"Link\": \"https://github.com/paderborn-university/mpe\"\\n      }\\n    ]\\n  },\\n  \"Learning Resources\": [\\n    {\\n      \"Type\": \"Books\",\\n      \"Title\": \"Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations\",\\n      \"Authors\": \"Yoav Shoham & Kevin Leyton-Brown\",\\n      \"Link\": \"https://www.masfoundations.org/\"\\n    },\\n    {\\n      \"Type\": \"Courses\",\\n      \"Title\": \"Multi-Agent Systems (Coursera)\",\\n      \"Description\": \"Courses by universities like University of Alberta or Georgia Tech on Coursera/edX.\",\\n      \"Link\": \"https://www.coursera.org/\"\\n    },\\n    {\\n      \"Type\": \"Online Tutorials\",\\n      \"Title\": \"MARLlib Tutorials\",\\n      \"Description\": \"Official tutorials for MARLlib and RLlib on the Ray documentation.\",\\n      \"Link\": \"https://docs.ray.io/en/latest/rllib/multi-agent.html\"\\n    }\\n  ]\\n}\\n}', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2225, 'prompt_tokens': 57, 'total_tokens': 2282, 'completion_time': 5.428169812, 'prompt_time': 0.005855109, 'queue_time': 0.086859753, 'total_time': 5.434024921}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'stop', 'logprobs': None}, id='run--af7f3224-3ee5-4d35-b346-f6ce7cd2a8ba-0', usage_metadata={'input_tokens': 57, 'output_tokens': 2225, 'total_tokens': 2282})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt|model\n",
    "response = chain.invoke({\"input\": \"What do you know about Agentic AI? and How to get Started? List down all the Opensource tools and resources.\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50211f49",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: Here is the output in the format you requested:\n\n{\"setup\": \"Why don't scientists trust atoms?\", \"punchline\": \"Because they make up everything!\"}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:88\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:150\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    149\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:166\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:123\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\json\\decoder.py:344\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    342\u001b[39m \n\u001b[32m    343\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\json\\decoder.py:362\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     29\u001b[39m prompt = PromptTemplate(\n\u001b[32m     30\u001b[39m     template=\u001b[33m\"\u001b[39m\u001b[33mAnswer the user query.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{format_instructions}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     32\u001b[39m     partial_variables={\u001b[33m\"\u001b[39m\u001b[33mformat_instructions\u001b[39m\u001b[33m\"\u001b[39m: parser.get_format_instructions()},\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m chain = prompt | llm | parser\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoke_query\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:196\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Krish Naik Youtube\\Agentic AI Course\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:91\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     90\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: Here is the output in the format you requested:\n\n{\"setup\": \"Why don't scientists trust atoms?\", \"punchline\": \"Because they make up everything!\"}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "# model = ChatOpenAI(temperature=0)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=GROQ_BASE_URL,  # Important!\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=random.random(),\n",
    "    seed= 2 \n",
    "\n",
    ")\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cacc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assignment \n",
    "\"Assistant -> LLM -> Pydantic\"\n",
    "\"Product -> {Product Name, product details, tentative price in USD}\"\n",
    "\"Use Chat Prompt Template\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d7aa55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=GROQ_BASE_URL,  # Important!\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    model=\"llama3-8b-8192\"\n",
    ")\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Product(BaseModel):\n",
    "    product_name: str = Field(description=\"Generate a Product name\")\n",
    "    product_details: str = Field(description=\"Generate product details\")\n",
    "    tentative_price: int = Field(description=\"Tentative price\")\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Product)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert retailer and know a lot about the retail industry. You have knowledge about more than 10,000 products.\\n\"\n",
    "            \"Strictly follow the output instructions: {format_instructions}\\n\"\n",
    "            \"Respond with only valid JSON and nothing else. Do not include any explanation or markdown formatting.\\n\"\n",
    "        ),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# PARTIAL the format_instructions so you don't have to supply it each time\n",
    "partial_prompt = prompt.partial(format_instructions=format_instructions)\n",
    "\n",
    "chain = partial_prompt | llm | parser\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "product_query = \"Tell me about Iphone 16 pro.\"\n",
    "result = chain.invoke({\"input\": product_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b567c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_name='iPhone 16 Pro' product_details=\"The latest addition to the iPhone series, iPhone 16 Pro features a 6.7-inch OLED display, powered by Apple's A16 Bionic chip, and comes with up to 16GB of RAM and 512GB of internal storage.\" tentative_price=1299\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d931d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95b74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3134d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cae2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
